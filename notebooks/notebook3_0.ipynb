{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant 3 processing\n",
    "1. Read the data\n",
    "1. Perform interquartile range smoothing for outlier\n",
    "1. Normalize the data to (-1, 1)\n",
    "1. Calculate the Heart rate (BPM) and respiration rate (BPM)\n",
    "    - save the data into .npy files\n",
    "1. Resample the data to same cardinality\n",
    "1. Correlation test\n",
    "1. Linear Regression\n",
    "    - export model\n",
    "1. Polynomial Regression\n",
    "    - export model\n",
    "1. Support Vector Regression (SVR)\n",
    "    - export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of libraries/modules\n",
    "### -------------------------------------------\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "### ------------------------------------------- \n",
    "import scipy\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "### -------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "### -------------------------------------------\n",
    "import numpy as np\n",
    "### -------------------------------------------\n",
    "import pandas as pd\n",
    "### -------------------------------------------\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "### -------------------------------------------\n",
    "import functools\n",
    "### -------------------------------------------\n",
    "import seaborn as sns\n",
    "### -------------------------------------------\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Custom Function\n",
    "def time2Num(time, fs):\n",
    "    num = time * fs\n",
    "    return int(num)\n",
    "\n",
    "\n",
    "def num2Time(num, fs):\n",
    "    time = num / fs\n",
    "    return time\n",
    "\n",
    "\n",
    "def secs2minutes(time):\n",
    "    return time / 60\n",
    "\n",
    "\n",
    "def minutes2secs(time):\n",
    "    return time * 60\n",
    "\n",
    "\n",
    "def secs2hours(time):\n",
    "    return time / 3600\n",
    "\n",
    "\n",
    "def hours2secs(time):\n",
    "    return time * 3600\n",
    "\n",
    "\n",
    "def iqr_remove_outlier(x, lower, upper):\n",
    "    if (x < lower):\n",
    "        return lower\n",
    "    elif (x > upper): \n",
    "        return upper\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def correlationTest(signal_1, signal_2, plot=True):\n",
    "    # Inspect by scatter plot\n",
    "    if plot: \n",
    "        plt.scatter(signal_1, signal_2)\n",
    "    # Covariance\n",
    "    covariance = np.cov(signal_1, signal_2)\n",
    "    print(covariance)\n",
    "    # calculate Pearson's correlation - 0 is no correlation -1 or 1 is highly correlated\n",
    "    corr, _ = scipy.stats.pearsonr(signal_1, signal_2)\n",
    "    print('Pearsons correlation: %.3f' % corr)\n",
    "    # calculate spearman's correlation - 0 is no correlation -1 or 1 is highly correlated\n",
    "    corr, _ = scipy.stats.spearmanr(signal_1, signal_2)\n",
    "    print('Spearmans correlation: %.3f' % corr)\n",
    "\n",
    "\n",
    "def peaks_hr(sig, peak_inds, fs, title, figsize=(20, 10), saveto=None):\n",
    "    \"Plot a signal with its peaks and heart rate\"\n",
    "    # Calculate heart rate\n",
    "    hrs = processing.hr.compute_hr(sig_len=sig.shape[0], qrs_inds=peak_inds, fs=fs)\n",
    "    \n",
    "    N = sig.shape[0]\n",
    "    \n",
    "    fig, ax_left = plt.subplots(figsize=figsize)\n",
    "    ax_right = ax_left.twinx()\n",
    "    \n",
    "    ax_left.plot(sig, color='#3979f0', label='Signal')\n",
    "    ax_left.plot(peak_inds, sig[peak_inds], 'rx', marker='x', \n",
    "                 color='#8b0000', label='Peak', markersize=12)\n",
    "    ax_right.plot(np.arange(N), hrs, label='Heart rate', color='m', linewidth=2)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "\n",
    "    ax_left.set_xlabel('Time (ms)')\n",
    "    ax_left.set_ylabel('ECG (mV)', color='#3979f0')\n",
    "    ax_right.set_ylabel('Heart rate (bpm)', color='m')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    ax_left.tick_params('y', colors='#3979f0')\n",
    "    ax_right.tick_params('y', colors='m')\n",
    "    if saveto is not None:\n",
    "        plt.savefig(saveto, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def peaks_rr(sig, peak_inds, fs, title, figsize=(20, 10), saveto=None):\n",
    "    \"Plot a signal with its peaks and heart rate\"\n",
    "    # Calculate heart rate\n",
    "    hrs = processing.hr.compute_hr(sig_len=sig.shape[0], qrs_inds=peak_inds, fs=fs)\n",
    "    \n",
    "    N = sig.shape[0]\n",
    "    \n",
    "    fig, ax_left = plt.subplots(figsize=figsize)\n",
    "    ax_right = ax_left.twinx()\n",
    "    \n",
    "    ax_left.plot(sig, color='#3979f0', label='Signal')\n",
    "    ax_left.plot(peak_inds, sig[peak_inds], 'rx', marker='x', \n",
    "                 color='#8b0000', label='Peak', markersize=12)\n",
    "    ax_right.plot(np.arange(N), hrs, label='Repiration rate', color='m', linewidth=2)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "\n",
    "    ax_left.set_xlabel('Time (ms)')\n",
    "    ax_left.set_ylabel('RESP (NU)', color='#3979f0')\n",
    "    ax_right.set_ylabel('Repiration rate (bpm)', color='m')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    ax_left.tick_params('y', colors='#3979f0')\n",
    "    ax_right.tick_params('y', colors='m')\n",
    "    if saveto is not None:\n",
    "        plt.savefig(saveto, dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "infantNum = 3\n",
    "ECG_dataset = f\"{data_dir}/infant{infantNum}_ecg\"\n",
    "RESP_dataset = f\"{data_dir}/infant{infantNum}_resp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Data(filename, startNum, endNum):\n",
    "    signal = wfdb.rdsamp(filename, sampfrom=startNum, sampto=endNum)\n",
    "    startTime_seconds = startNum/signal[1]['fs']\n",
    "    endTime_seconds = endNum/signal[1]['fs']\n",
    "    return signal, startTime_seconds, endTime_seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interquartile (IQR) Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_iqr(signal, hiPerc, loPerc):\n",
    "    hiPerc_val, loPerc_val = np.percentile(signal, [hiPerc, loPerc])\n",
    "    iqr = hiPerc_val - loPerc_val\n",
    "    print(f\"{hiPerc}th percentile: {hiPerc_val}, {loPerc}th percentile: {loPerc_val}, IQR: {iqr}\")\n",
    "    return iqr, hiPerc_val, loPerc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_smooth(signal, hiPerc, loPerc, cutoff_factor=0.5):\n",
    "    # calculate the outlier cutoff\n",
    "    iqr, hiPerc_val, loPerc_val = cal_iqr(signal, hiPerc=hiPerc, loPerc=loPerc)\n",
    "    cutoff = iqr * cutoff_factor\n",
    "    lower, upper = loPerc_val - cutoff, hiPerc_val + cutoff\n",
    "    # identify outliers\n",
    "    outliers = [x for x in signal if x < lower or x > upper]\n",
    "    print('Identified outliers: %d' % len(outliers))\n",
    "    output = map(functools.partial(iqr_remove_outlier, lower=lower, upper=upper), signal)\n",
    "    output = np.fromiter(output, dtype=np.float64)\n",
    "    print(f\"Data Shape: {output.shape}\")\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization (-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_signal(signal, max=1, min=-1):\n",
    "    scaler = MinMaxScaler(feature_range=(min,max))\n",
    "    output = scaler.fit_transform(signal.reshape((-1,1)))\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Rate and Respiration Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_heartrate(signal, fs):\n",
    "    qrs_inds = processing.qrs.gqrs_detect(sig=signal.reshape(signal.shape[0]), fs=fs)\n",
    "    hrs = processing.hr.compute_hr(sig_len=signal.shape[0], qrs_inds=qrs_inds, fs=fs)\n",
    "    return hrs\n",
    "\n",
    "\n",
    "def cal_resprate(signal, fs):\n",
    "    peaks_inds = processing.peaks.find_local_peaks(sig=signal.reshape(signal.shape[0]), radius=fs)\n",
    "    rrs = processing.hr.compute_hr(sig_len=signal.shape[0], qrs_inds=peaks_inds, fs=fs)\n",
    "    return rrs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Data & Fix NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fixNan(signal):\n",
    "    output = pd.DataFrame(signal).fillna(0).to_numpy().reshape(signal.shape[0])\n",
    "    return output\n",
    "\n",
    "\n",
    "def data_resample(signal, sig_len):\n",
    "    output = scipy.signal.resample(signal, sig_len)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_model(X, y, test_size = 0.25, **kwargs):\n",
    "    \n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "\n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    lr_model = LinearRegression().fit(X_train, y_train)\n",
    "    r_sq = lr_model.score(X_train, y_train)\n",
    "    print(f\"Coefficient of determination: {r_sq}\")\n",
    "    print(f\"Intercept: {lr_model.intercept_}\")\n",
    "    print(f\"Coefficients: {lr_model.coef_}\")\n",
    "    y_test_predict = lr_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_test_predict)\n",
    "    mse = mean_squared_error(y_test, y_test_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade_train_lr_model(model, X, y, test_size = 0.25, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    r_sq = model.score(X_train, y_train)\n",
    "    print(f\"Coefficient of determination: {r_sq}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "    print(f\"Coefficients: {model.coef_}\")\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_test_predict)\n",
    "    mse = mean_squared_error(y_test, y_test_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pr_model(X, y, degree=2, test_size = 0.25, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    transformer = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = transformer.fit_transform(X_train)\n",
    "    X_test_poly = transformer.fit_transform(X_test)\n",
    "    pr_model = LinearRegression().fit(X_train_poly, y_train)\n",
    "    r_sq = pr_model.score(X_train_poly, y_train)\n",
    "    print(f\"Coefficient of determination: {r_sq}\")\n",
    "    print(f\"Intercept: {pr_model.intercept_}\")\n",
    "    print(f\"Coefficients: {pr_model.coef_}\")\n",
    "    y_test_predict = pr_model.predict(X_test_poly)\n",
    "    mae = mean_absolute_error(y_test, y_test_predict)\n",
    "    mse = mean_squared_error(y_test, y_test_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    return pr_model\n",
    "\n",
    "\n",
    "def cascade_train_pr_model(model, X, y, degree=2, test_size = 0.25, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    transformer = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = transformer.fit_transform(X_train)\n",
    "    X_test_poly = transformer.fit_transform(X_test)\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    r_sq = model.score(X_train_poly, y_train)\n",
    "    print(f\"Coefficient of determination: {r_sq}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "    print(f\"Coefficients: {model.coef_}\")\n",
    "    y_test_predict = model.predict(X_test_poly)\n",
    "    mae = mean_absolute_error(y_test, y_test_predict)\n",
    "    mse = mean_squared_error(y_test, y_test_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr_model(X, y, test_size = 0.25, scaler='MinMax', param_C=1, param_gamma=0.1, param_degree=2, param_epsilon=0.1, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    svr_rbf = SVR(kernel='rbf', C=param_C, gamma=param_gamma, epsilon=param_epsilon)\n",
    "    svr_lin = SVR(kernel='linear', C=param_C)\n",
    "    svr_poly = SVR(kernel='poly', C=param_C, degree=param_degree, epsilon=param_epsilon)\n",
    "\n",
    "    # Train models\n",
    "    svr_rbf.fit(X_train_l, y_train_p.ravel())\n",
    "    svr_lin.fit(X_train_l, y_train_p.ravel())\n",
    "    svr_poly.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_rbf = svr_rbf.score(X_train_l, y_train_p)\n",
    "    r_sq_lin = svr_lin.score(X_train_l, y_train_p)\n",
    "    r_sq_poly = svr_poly.score(X_train_l, y_train_p)\n",
    "    print(\"SVR Radial Basis Function (RBF)\")\n",
    "    print(f\"Coefficient of determination: {r_sq_rbf}\")\n",
    "    print(f\"Intercept: {svr_rbf.intercept_}\")\n",
    "    print(\"SVR Linear\")\n",
    "    print(f\"Coefficient of determination: {r_sq_lin}\")\n",
    "    print(f\"Intercept: {svr_lin.intercept_}\")\n",
    "    print(\"SVR Polynomial\")\n",
    "    print(f\"Coefficient of determination: {r_sq_poly}\")\n",
    "    print(f\"Intercept: {svr_poly.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_rbf = svr_rbf.predict(X_test_l)\n",
    "    y_test_p_predict_lin = svr_lin.predict(X_test_l)\n",
    "    y_test_p_predict_poly = svr_poly.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_rbf = MinMax_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "        y_test_predict_lin = MinMax_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "        y_test_predict_poly = MinMax_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_rbf = StdS_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "        y_test_predict_lin = StdS_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "        y_test_predict_poly = StdS_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    \n",
    "    print(\"SVR Radial Basis Function (RBF)\")\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_rbf)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_rbf)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    print(\"SVR Linear\")\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_lin)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_lin)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    print(\"SVR Polynomial\")\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_poly)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_poly)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return svr_rbf, svr_lin, svr_poly\n",
    "\n",
    "\n",
    "def train_svr_rbf_model(X, y, test_size = 0.25, scaler='MinMax', param_C=1, param_gamma=0.1, param_epsilon=0.1, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    svr_rbf = SVR(kernel='rbf', C=param_C, gamma=param_gamma, epsilon=param_epsilon)\n",
    "\n",
    "    # Train models\n",
    "    svr_rbf.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_rbf = svr_rbf.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_rbf}\")\n",
    "    print(f\"Intercept: {svr_rbf.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_rbf = svr_rbf.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_rbf = MinMax_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_rbf = StdS_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_rbf)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_rbf)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return svr_rbf\n",
    "\n",
    "\n",
    "def cascade_train_svr_rbf_model(model, X, y, test_size = 0.25, scaler='MinMax', **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    # svr_rbf = SVR(kernel='rbf', C=param_C, gamma=param_gamma, epsilon=param_epsilon)\n",
    "\n",
    "    # Train models\n",
    "    model.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_rbf = model.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_rbf}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_rbf = model.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_rbf = MinMax_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_rbf = StdS_y.inverse_transform(y_test_p_predict_rbf.reshape(-1,1))\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_rbf)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_rbf)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_svr_lin_model(X, y, test_size = 0.25, scaler='MinMax', param_C=1, param_gamma='auto', **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    svr_lin = SVR(kernel='linear', C=param_C, gamma=param_gamma)\n",
    "\n",
    "    # Train models\n",
    "    svr_lin.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_lin = svr_lin.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_lin}\")\n",
    "    print(f\"Intercept: {svr_lin.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_lin = svr_lin.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_lin = MinMax_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_lin = StdS_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_lin)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_lin)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return svr_lin\n",
    "\n",
    "\n",
    "def cascade_train_svr_lin_model(model, X, y, test_size = 0.25, scaler='MinMax', **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    # svr_lin = SVR(kernel='linear', C=param_C, gamma=param_gamma)\n",
    "\n",
    "    # Train models\n",
    "    model.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_lin = model.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_lin}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_lin = model.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_lin = MinMax_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_lin = StdS_y.inverse_transform(y_test_p_predict_lin.reshape(-1,1))\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_lin)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_lin)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_svr_poly_model(X, y, test_size = 0.25, scaler='MinMax', param_C=1, param_gamma='auto', param_degree=2, param_epsilon=0.1, **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    svr_poly = SVR(kernel='poly', C=param_C, gamma=param_gamma, epsilon=param_epsilon, degree=param_degree)\n",
    "\n",
    "    # Train models\n",
    "    svr_poly.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_poly = svr_poly.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_poly}\")\n",
    "    print(f\"Intercept: {svr_poly.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_poly = svr_poly.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_poly = MinMax_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_y_test_predict_polylin = StdS_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_poly)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_poly)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return svr_poly\n",
    "\n",
    "\n",
    "def cascade_train_svr_poly_model(model, X, y, test_size = 0.25, scaler='MinMax', **kwargs):\n",
    "    X = X.reshape((-1,1))\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    if 'seed' in kwargs:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=kwargs['seed'])\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # feature scaling\n",
    "    if scaler == 'MinMax':\n",
    "        MinMax_X = MinMaxScaler()\n",
    "        MinMax_y = MinMaxScaler()\n",
    "        X_train_l = MinMax_X.fit_transform(X_train)\n",
    "        y_train_p = MinMax_y.fit_transform(y_train)\n",
    "        X_test_l = MinMax_X.fit_transform(X_test)\n",
    "        y_test_p = MinMax_y.fit_transform(y_test)\n",
    "    else: \n",
    "        StdS_X = StandardScaler()\n",
    "        StdS_y = StandardScaler()\n",
    "        X_train_l = StdS_X.fit_transform(X_train)\n",
    "        y_train_p = StdS_y.fit_transform(y_train)\n",
    "        X_test_l = StdS_X.fit_transform(X_test)\n",
    "        y_test_p = StdS_y.fit_transform(y_test)\n",
    "    \n",
    "    # Create models \n",
    "    # svr_poly = SVR(kernel='poly', C=param_C, gamma=param_gamma, epsilon=param_epsilon, degree=param_degree)\n",
    "\n",
    "    # Train models\n",
    "    model.fit(X_train_l, y_train_p.ravel())\n",
    "\n",
    "    r_sq_poly = model.score(X_train_l, y_train_p)\n",
    "    print(f\"Coefficient of determination: {r_sq_poly}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "    y_test_p_predict_poly = model.predict(X_test_l)\n",
    "\n",
    "    if scaler == 'MinMax':\n",
    "        y_test_predict_poly = MinMax_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    else:\n",
    "        y_test_predict_y_test_predict_polylin = StdS_y.inverse_transform(y_test_p_predict_poly.reshape(-1,1))\n",
    "    mae = mean_absolute_error(y_test, y_test_predict_poly)\n",
    "    mse = mean_squared_error(y_test, y_test_predict_poly)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG DATA: {'fs': 500, 'sig_len': 78684614, 'n_sig': 1, 'base_date': None, 'base_time': None, 'units': ['mV'], 'sig_name': ['II'], 'comments': []}\n",
      "RESP DATA: {'fs': 50, 'sig_len': 7868296, 'n_sig': 1, 'base_date': None, 'base_time': None, 'units': ['NU'], 'sig_name': ['RESP'], 'comments': []}\n"
     ]
    }
   ],
   "source": [
    "# Read all the data\n",
    "signal_ecg_0 = wfdb.rdsamp(f\"{data_dir}/infant{infantNum}_ecg\")\n",
    "signal_resp_0 = wfdb.rdsamp(f\"{data_dir}/infant{infantNum}_resp\")\n",
    "print(f'ECG DATA: {signal_ecg_0[1]}')\n",
    "print(F'RESP DATA: {signal_resp_0[1]}')\n",
    "# signal_ECG = read_Data(ECG_dataset, startNum=0, endNum=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157369.228 sec, 2622.8204666666666 minutes, 43.71367444444444 hours\n"
     ]
    }
   ],
   "source": [
    "totalDuration_ECG = num2Time(num=signal_ecg_0[1]['sig_len'], fs=signal_ecg_0[1]['fs'])\n",
    "print(f'{totalDuration_ECG} sec, {secs2minutes(totalDuration_ECG)} minutes, {secs2hours(totalDuration_ECG)} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 1800000, end: 3600000\n",
      "start: 180000, end: 360000\n"
     ]
    }
   ],
   "source": [
    "# Start and end time defined\n",
    "start_time_secs = hours2secs(1)\n",
    "end_time_secs = hours2secs(2)\n",
    "\n",
    "ECG_startNum = time2Num(start_time_secs, signal_ecg_0[1]['fs'])\n",
    "ECG_endNum = time2Num(end_time_secs, signal_ecg_0[1]['fs'])\n",
    "print(f'start: {ECG_startNum}, end: {ECG_endNum}')\n",
    "RESP_startNum = time2Num(start_time_secs, signal_resp_0[1]['fs'])\n",
    "RESP_endNum = time2Num(end_time_secs, signal_resp_0[1]['fs'])\n",
    "print(f'start: {RESP_startNum}, end: {RESP_endNum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ECG, signal_ECG_startTime_secs, signal_ECG_endTime_secs = read_Data(ECG_dataset, startNum=ECG_startNum, endNum=ECG_endNum)\n",
    "signal_RESP, signal_RESP_startTime_secs, signal_RESP_endTime_secs = read_Data(RESP_dataset, startNum=RESP_startNum, endNum=RESP_endNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800000, 1)\n",
      "90th percentile: 0.12798088070831984, 10th percentile: -0.17005678669461677, IQR: 0.2980376674029366\n",
      "Identified outliers: 79092\n",
      "Data Shape: (1800000,)\n",
      "(180000, 1)\n",
      "90th percentile: 23.419280576061812, 10th percentile: 21.09773410503232, IQR: 2.3215464710294924\n",
      "Identified outliers: 934\n",
      "Data Shape: (180000,)\n"
     ]
    }
   ],
   "source": [
    "print(signal_ECG[0].shape)\n",
    "signal_ECG_1 = iqr_smooth(signal=signal_ECG[0],hiPerc=90,loPerc=10, cutoff_factor=1.5)\n",
    "print(signal_RESP[0].shape)\n",
    "signal_RESP_1 = iqr_smooth(signal=signal_RESP[0],hiPerc=90,loPerc=10, cutoff_factor=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ECG_2 = norm_signal(signal=signal_ECG_1)\n",
    "signal_RESP_2 = norm_signal(signal=signal_RESP_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs_0 = cal_heartrate(signal=signal_ECG_2, fs=signal_ECG[1]['fs'])\n",
    "rrs_0 = cal_resprate(signal=signal_RESP_2, fs=signal_RESP[1]['fs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (rrs_0.shape[0] < hrs_0.shape[0]):\n",
    "    hrs_1 = data_resample(data_fixNan(hrs_0), rrs_0.shape[0])\n",
    "    rrs_1 = data_fixNan(rrs_0)\n",
    "else:\n",
    "    rrs_1 = data_resample(data_fixNan(rrs_0), hrs_0.shape[0])\n",
    "    hrs_1 = data_fixNan(hrs_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52.309414  -10.458236    5.7722535 ... 119.45426   110.43015\n",
      " 125.91644  ]\n",
      "[ 0.        0.        0.       ... 30.927835 30.927835 30.927835]\n"
     ]
    }
   ],
   "source": [
    "print(hrs_1)\n",
    "print(rrs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160.48146965 -21.74480548]\n",
      " [-21.74480548 160.40714127]]\n",
      "Pearsons correlation: -0.136\n",
      "Spearmans correlation: -0.206\n"
     ]
    }
   ],
   "source": [
    "correlationTest(rrs_1[:],hrs_1[:], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "--- Linear Regression ---\n",
      "Coefficient of determination: 0.018250025191659858\n",
      "Intercept: [130.04575]\n",
      "Coefficients: [[-0.13510673]]\n",
      "Mean absolute error: 8.56\n",
      "Mean squared error: 157.23\n",
      "Root mean squared error: 12.54\n",
      "---------------------------------------------\n",
      "--- Polynomial Regression ---\n",
      "Coefficient of determination: 0.026462602305085015\n",
      "Intercept: [127.47017]\n",
      "Coefficients: [[ 4.0392306e-10  9.4348724e-09  3.7569964e-07  5.9631006e-06\n",
      "  -3.3849508e-07  4.0051282e-09]]\n",
      "Mean absolute error: 8.56\n",
      "Mean squared error: 158.76\n",
      "Root mean squared error: 12.60\n",
      "---------------------------------------------\n",
      "--- SVR ---\n",
      "SVR Radial Basis Function (RBF)\n",
      "Coefficient of determination: -0.1043429559831861\n",
      "Intercept: [0.1822884]\n",
      "SVR Linear\n",
      "Coefficient of determination: -0.17089279679719538\n",
      "Intercept: [0.55173055]\n",
      "SVR Polynomial\n",
      "Coefficient of determination: -0.1643583433300433\n",
      "Intercept: [0.55534475]\n",
      "SVR Radial Basis Function (RBF)\n",
      "Mean absolute error: 8.70\n",
      "Mean squared error: 157.80\n",
      "Root mean squared error: 12.56\n",
      "SVR Linear\n",
      "Mean absolute error: 9.03\n",
      "Mean squared error: 162.42\n",
      "Root mean squared error: 12.74\n",
      "SVR Polynomial\n",
      "Mean absolute error: 8.98\n",
      "Mean squared error: 161.51\n",
      "Root mean squared error: 12.71\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------\")\n",
    "print(\"--- Linear Regression ---\")\n",
    "lr_model_1 = train_lr_model(X=rrs_1, y=hrs_1)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"--- Polynomial Regression ---\")\n",
    "pr_model_1 = train_pr_model(X=rrs_1, y=hrs_1, degree=6)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"--- SVR ---\")\n",
    "svr_rbf_1, svr_lin_1, svr_poly_1 = train_svr_model(X=rrs_1, y=hrs_1)\n",
    "# svr_rbf_1 = train_svr_rbf_model(X=rrs_1, y=hrs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcs_aml_venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14dbdb1f72aaa09167b48d00cde9d80f1c9c9222724b1b54b66fa4b88a3fbfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
